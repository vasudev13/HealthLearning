{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MedNLI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8e5f9385f35457e892f9b602dfb8546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7f6c9187da64a34b984f36a6af71a84",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_564ba44b7a4943f0bab2abb2be4801c6",
              "IPY_MODEL_40c43dd7106646518965eac2fc4211b0"
            ]
          }
        },
        "d07156a3379e4b62b124c34d6b614643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0792583f29c1416585008c08732299a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_583fe45cb35049e4ac1e55757031715f",
              "IPY_MODEL_f64fa42eae474a4c8f3c570e7296f8d0"
            ]
          }
        },
        "8473a40a64f349168a5da693c122b0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_714a8adcd63e4027ab5c8b020cd46848",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa2cdc6e7e79420bae526ea26b6d5fdf",
              "IPY_MODEL_27a031866a5a4097bbce40914dce4e4f"
            ]
          }
        },
        "20ac5951d8e14c76a11743e97c572c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_267ff477bdd64c7d95cc5ba0ac29c325",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41779b41eedd4783baefc30d83a9ecfa",
              "IPY_MODEL_e8ae0c9c4e144967872d4d91e41d4e40"
            ]
          }
        },
        "b9eb6bbf864a4edf92b5b72601ec3352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba4fb451c73141708c50efca50e88954",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_acb9b1254fdd416e8d39e5d9cf5ad101",
              "IPY_MODEL_d1ec4400c2914d02a12561b1b7e2c211"
            ]
          }
        },
        "4814d7112c3e490b887ca10354563c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_209bfc5b0c6940a28cf3ce0351b878e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31ab0fabf1b94e33841995dfd70e3753",
              "IPY_MODEL_aada892f80d14ba79b28be2f8c3e7a1e"
            ]
          }
        },
        "5c688bbff25d45d69856f370cbcb49ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6329fc1096eb4125803631509bd0d247",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0cb6837c36a411f91c1135466473666",
              "IPY_MODEL_bfc7bba2aa3e4161bb42015794b2b1fe"
            ]
          }
        },
        "eabc600ea8fa46fb9d8e935880e5a1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9ff63f766a64ceb94e3a7d1607f4067",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c73f97cddb648d2ae0962c7b2727b62",
              "IPY_MODEL_2e7a99602e0b438382b33cdb00864ce9"
            ]
          }
        },
        "fcbcbafad72c4504a521975423c3a37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fc41cc2e6d184568acf0b1ae77049e6e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a92fae4ee84c45debd3a748c6daa5d08",
              "IPY_MODEL_6f5f8a458c0b40a083775cf1c208cec6"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HV3iaYiHpMt"
      },
      "source": [
        "%%capture\n",
        "!gdown --id 1zPTj8nVmagH8BAxP_NG1Uj_mHdVdTS32\n",
        "!pip install transformers\n",
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXP4a68ySwf6",
        "outputId": "87039e87-f102-4504-c34f-493ce060f678"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 15 06:54:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyOsz0GsKouY"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laOI3ayiHioT"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import torchmetrics\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import zipfile"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y46F4WeKkpCB"
      },
      "source": [
        "CONFIG={\n",
        "    'ZIP_PATH':'./mednli-a-natural-language-inference-dataset-for-the-clinical-domain-1.0.0.zip', # PATH TO ZIP FILE\n",
        "    'DATA_PATH':'./mednli-a-natural-language-inference-dataset-for-the-clinical-domain-1.0.0', # PATH TO UNZIP DATASET\n",
        "    'sentence1':'sentence1',\n",
        "    'sentence2':'sentence2',\n",
        "    'labels':'gold_label',\n",
        "    'SEED':13,\n",
        "    'MAX_LEN':256,\n",
        "    'MODEL_NAME_OR_PATH':'dmis-lab/biobert-v1.1',\n",
        "    'LEARNING_RATE':2e-5,\n",
        "    'ADAM_EPSILON':1e-8,\n",
        "    'WEIGHT_DECAY':0.0,\n",
        "    'NUM_CLASSES':3,\n",
        "    'TRAIN_BS':32,\n",
        "    'VAL_BS':32,\n",
        "    'WARMUP_STEPS':0,\n",
        "    'MAX_EPOCHS':2,\n",
        "    'CHECKPOINT_DIR':'./checkpoints',\n",
        "    'NUM_WORKERS':2,\n",
        "    'PRECISION':16,\n",
        "    'MODEL_SAVE_NAME':'biobert_v1'\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqDpGKcEJBoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726f80e8-7572-4e1f-a67e-42c9aca161cb"
      },
      "source": [
        "_=pl.seed_everything(CONFIG['SEED'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 13\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q1gW3DLOZHW"
      },
      "source": [
        "class NLIDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self,max_len:int,tokenizer,sentence1,sentence2,labels):\n",
        "    super().__init__()\n",
        "    self.max_len=max_len\n",
        "    self.tokenizer=tokenizer\n",
        "    self.sentence1=sentence1\n",
        "    self.sentence2=sentence2\n",
        "    self.labels=labels\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.sentence1)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    sentence_1=self.sentence1[idx]\n",
        "    sentence_2=self.sentence2[idx]\n",
        "    encoded_input=self.tokenizer.encode_plus(\n",
        "        text=sentence_1,\n",
        "        text_pair=sentence_2,\n",
        "        add_special_tokens=True,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=self.max_len,\n",
        "        return_token_type_ids=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'labels':torch.tensor(self.labels[idx]),\n",
        "        'input_ids':encoded_input['input_ids'].view(-1),\n",
        "        'attention_mask':encoded_input['attention_mask'].view(-1),\n",
        "        'token_type_ids':encoded_input['token_type_ids'].view(-1),\n",
        "    }"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YbKth_jCi6d"
      },
      "source": [
        "def mnli_df(stage):\n",
        "  label_map={'entailment':0,'contradiction':1,'neutral':2}\n",
        "  df=pd.read_json(f\"{CONFIG['DATA_PATH']}/mli_{stage}_v1.jsonl\",lines=True,)\n",
        "  df=df[[CONFIG['sentence1'],CONFIG['sentence2'],CONFIG['labels']]]\n",
        "  df[CONFIG['labels']]=df[CONFIG['labels']].map(label_map)\n",
        "  return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdMeI0vDggMp"
      },
      "source": [
        "class NLIDataModel(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self,get_split_def):\n",
        "        super().__init__()\n",
        "        self.get_split_def=get_split_def\n",
        "\n",
        "    def prepare_data(self):\n",
        "        zip = zipfile.ZipFile(CONFIG['ZIP_PATH'])\n",
        "        zip.extractall()\n",
        "        self.tokenizer=transformers.AutoTokenizer.from_pretrained(CONFIG['MODEL_NAME_OR_PATH'])\n",
        "\n",
        "    def setup(self, stage):\n",
        "\n",
        "      if stage=='fit':\n",
        "        self.train_df,self.val_df=self.get_split_def('train'),self.get_split_def('dev')\n",
        "\n",
        "      if stage=='test':\n",
        "        self.test_df=self.get_split_def('test')\n",
        "\n",
        "    def get_dataset(self,df):\n",
        "      dataset = NLIDataset(max_len=CONFIG['MAX_LEN'],\n",
        "                               tokenizer=self.tokenizer,\n",
        "                               sentence1=df[CONFIG['sentence1']].values,\n",
        "                               sentence2=df[CONFIG['sentence2']].values,\n",
        "                               labels=df[CONFIG['labels']].values)\n",
        "      return dataset\n",
        "\n",
        "    def train_dataloader(self):\n",
        "      train_dataset=self.get_dataset(self.train_df)\n",
        "      train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                                     batch_size=CONFIG['TRAIN_BS'], \n",
        "                                                     shuffle=True, \n",
        "                                                     num_workers=CONFIG['NUM_WORKERS'])\n",
        "      \n",
        "      return train_dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "      val_dataset=self.get_dataset(self.val_df)\n",
        "      val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
        "                                                     batch_size=CONFIG['VAL_BS'], \n",
        "                                                     shuffle=False, \n",
        "                                                     num_workers=CONFIG['NUM_WORKERS'])\n",
        "      \n",
        "      return val_dataloader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "      test_dataset=self.get_dataset(self.test_df)\n",
        "      test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
        "                                                     batch_size=CONFIG['VAL_BS'], \n",
        "                                                     shuffle=False, \n",
        "                                                     num_workers=CONFIG['NUM_WORKERS'])\n",
        "      \n",
        "      return test_dataloader"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6roNgOB9JxT"
      },
      "source": [
        "class NLIFineTuningModel(pl.LightningModule):\n",
        "\n",
        "  def __init__(self,model_name_or_path:str,\n",
        "               num_labels:int,\n",
        "               learning_rate:float,\n",
        "               adam_epsilon:float,\n",
        "               weight_decay:float,\n",
        "               max_len:int,\n",
        "               warmup_steps:int,\n",
        "               gpus:int,max_epochs:int,accumulate_grad_batches:int):\n",
        "    super().__init__()\n",
        "    self.model_name_or_path=model_name_or_path\n",
        "    self.num_labels=num_labels\n",
        "    \n",
        "    self.save_hyperparameters('learning_rate','adam_epsilon','weight_decay','max_len','gpus','accumulate_grad_batches','max_epochs','warmup_steps') \n",
        "\n",
        "    self.config = transformers.AutoConfig.from_pretrained(model_name_or_path, num_labels=self.num_labels)\n",
        "    self.model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name_or_path, config=self.config)\n",
        "    # self.model = nn.Sequential( \n",
        "    #     OrderedDict(\n",
        "    #         [\n",
        "    #          ('base',transformers.AutoModel.from_pretrained(model_name_or_path)),\n",
        "    #          ('classifier',nn.Linear(in_features=768,out_features=self.num_labels)),\n",
        "    #          ('softmax',nn.Softmax())\n",
        "    #         ]\n",
        "    #     )\n",
        "    # )\n",
        "    metrics = torchmetrics.MetricCollection([\n",
        "        torchmetrics.Accuracy(),\n",
        "        torchmetrics.F1(num_classes=3,average='macro')\n",
        "      ]\n",
        "    )\n",
        "    self.train_metrics=metrics.clone()\n",
        "    self.val_metrics=metrics.clone()\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    return self.model(**inputs)\n",
        "  \n",
        "  def training_step(self,batch,batch_idx):\n",
        "    loss,logits=self(batch)[:2]\n",
        "    predictions=torch.argmax(logits,dim=1)\n",
        "    self.train_metrics(predictions,batch['labels'])\n",
        "    self.log_dict({'train_accuracy':self.train_metrics['Accuracy'],'train_f1':self.train_metrics['F1']}, on_step=False, on_epoch=True)\n",
        "    return {\n",
        "        'loss':loss,\n",
        "        'predictions':predictions,\n",
        "        'labels':batch['labels']\n",
        "    }\n",
        "  \n",
        "  def validation_step(self,batch,batch_idx):\n",
        "    loss,logits=self(batch)[:2]\n",
        "    predictions=torch.argmax(logits,dim=1)\n",
        "    self.val_metrics(predictions,batch['labels'])\n",
        "    self.log_dict({'val_accuracy':self.val_metrics['Accuracy'],'val_f1':self.val_metrics['F1']}, on_step=False, on_epoch=True)\n",
        "    return {\n",
        "        'loss':loss,\n",
        "        'predictions':predictions,\n",
        "        'labels':batch['labels']\n",
        "    }\n",
        "  \n",
        "  def test_step(self,batch,batch_idx):\n",
        "    loss,logits=self(batch)[:2]\n",
        "    predictions=torch.argmax(logits,dim=1)\n",
        "    self.val_metrics(predictions,batch['labels'])\n",
        "    self.log_dict({'test_accuracy':self.val_metrics['Accuracy'],'test_f1':self.val_metrics['F1']}, on_step=False, on_epoch=True)\n",
        "    return {\n",
        "        'loss':loss,\n",
        "        'predictions':predictions,\n",
        "        'labels':batch['labels']\n",
        "    }\n",
        "\n",
        "  def test_epoch_end(self,outputs):\n",
        "    loss=torch.tensor([x['loss'] for x in outputs])\n",
        "    loss = loss.mean()\n",
        "    self.log('test_loss', loss, prog_bar=True,on_step=False, on_epoch=True )\n",
        "\n",
        "  def validation_epoch_end(self,outputs):\n",
        "    loss=torch.tensor([x['loss'] for x in outputs])\n",
        "    loss = loss.mean()\n",
        "    self.log('val_loss', loss, prog_bar=True,on_step=False, on_epoch=True )\n",
        "  \n",
        "  def training_epoch_end(self,outputs):\n",
        "    loss=torch.tensor([x['loss'] for x in outputs])\n",
        "    loss = loss.mean()\n",
        "    self.log('train_loss', loss, prog_bar=True,on_step=False, on_epoch=True )\n",
        "  \n",
        "  def setup(self, stage):\n",
        "    if stage == 'fit':\n",
        "      train_loader = self.train_dataloader()\n",
        "      self.total_steps = (\n",
        "          (len(train_loader.dataset) // (train_loader.batch_size * max(1, self.hparams.gpus)))\n",
        "          // self.hparams.accumulate_grad_batches * float(self.hparams.max_epochs)\n",
        "      )\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    model = self.model\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\",\"LayerNorm.bias\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "          {\n",
        "              \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "              \"weight_decay\": self.hparams.weight_decay,\n",
        "          },\n",
        "          {\n",
        "              \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "              \"weight_decay\": 0.0,\n",
        "          },\n",
        "    ]\n",
        "    optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.total_steps\n",
        "    )\n",
        "    scheduler = {\n",
        "        'scheduler': scheduler,\n",
        "        'interval': 'step',\n",
        "        'frequency': 1\n",
        "    }\n",
        "    return [optimizer] ,[scheduler]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-zsAoT-Ggwz"
      },
      "source": [
        "model_save_checkpoint = pl.callbacks.ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    dirpath=CONFIG['CHECKPOINT_DIR'],\n",
        "    filename=f\"{CONFIG['MODEL_SAVE_NAME']}\"+'-{epoch:02d}-{val_loss:.2f}',\n",
        "    save_top_k=1,\n",
        "    mode='min',\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuzWNRU_LqoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f33825d-c08e-470e-c4c6-3d844d6f4004"
      },
      "source": [
        "trainer = pl.Trainer(gpus=torch.cuda.device_count(),\n",
        "                     max_epochs=CONFIG['MAX_EPOCHS'],\n",
        "                     callbacks=[model_save_checkpoint],\n",
        "                     precision=CONFIG['PRECISION'],\n",
        "                     num_sanity_val_steps=0\n",
        "                    )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAsiFQk9sIyX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402,
          "referenced_widgets": [
            "c8e5f9385f35457e892f9b602dfb8546",
            "d07156a3379e4b62b124c34d6b614643",
            "8473a40a64f349168a5da693c122b0e7",
            "20ac5951d8e14c76a11743e97c572c55",
            "b9eb6bbf864a4edf92b5b72601ec3352",
            "4814d7112c3e490b887ca10354563c38",
            "5c688bbff25d45d69856f370cbcb49ac",
            "eabc600ea8fa46fb9d8e935880e5a1cf"
          ]
        },
        "outputId": "593a6bd0-b7d2-40d6-c28f-0766c4a69e61"
      },
      "source": [
        "model=NLIFineTuningModel(\n",
        "    model_name_or_path=CONFIG['MODEL_NAME_OR_PATH'],\n",
        "    num_labels=CONFIG['NUM_CLASSES'],\n",
        "    learning_rate=CONFIG['LEARNING_RATE'],\n",
        "    adam_epsilon=CONFIG['ADAM_EPSILON'],\n",
        "    weight_decay=CONFIG['WEIGHT_DECAY'],\n",
        "    max_len=CONFIG['MAX_LEN'],\n",
        "    warmup_steps=CONFIG['WARMUP_STEPS'],\n",
        "    max_epochs=trainer.max_epochs,\n",
        "    gpus=trainer.gpus,\n",
        "    accumulate_grad_batches=trainer.accumulate_grad_batches,\n",
        ")\n",
        "\n",
        "mnli_dm=NLIDataModel(get_split_def=mnli_df)\n",
        "trainer.fit(model,mnli_dm)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8e5f9385f35457e892f9b602dfb8546",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=462.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d07156a3379e4b62b124c34d6b614643",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433286112.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8473a40a64f349168a5da693c122b0e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20ac5951d8e14c76a11743e97c572c55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9eb6bbf864a4edf92b5b72601ec3352",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=49.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name          | Type                          | Params\n",
            "----------------------------------------------------------------\n",
            "0 | model         | BertForSequenceClassification | 108 M \n",
            "1 | train_metrics | MetricCollection              | 0     \n",
            "2 | val_metrics   | MetricCollection              | 0     \n",
            "----------------------------------------------------------------\n",
            "108 M     Trainable params\n",
            "0         Non-trainable params\n",
            "108 M     Total params\n",
            "433.250   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4814d7112c3e490b887ca10354563c38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c688bbff25d45d69856f370cbcb49ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eabc600ea8fa46fb9d8e935880e5a1cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVuzA8o-Vxnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3be092b-def0-4f8b-fb98-e3d93f45efda"
      },
      "source": [
        "trainer.logged_metrics"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': tensor(1.),\n",
              " 'train_accuracy': tensor(0.8374, device='cuda:0'),\n",
              " 'train_f1': tensor(0.8379, device='cuda:0'),\n",
              " 'train_loss': tensor(0.4386, device='cuda:0'),\n",
              " 'val_accuracy': tensor(0.8179),\n",
              " 'val_f1': tensor(0.8180),\n",
              " 'val_loss': tensor(0.4627)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQMDoVRl6LQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "fcbcbafad72c4504a521975423c3a37d"
          ]
        },
        "outputId": "fd123aa5-cae8-4529-84b6-a9aff67ad0ef"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcbcbafad72c4504a521975423c3a37d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_accuracy': 0.8016877770423889,\n",
            " 'test_f1': 0.8019723296165466,\n",
            " 'test_loss': 0.5160344839096069}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.8016877770423889,\n",
              "  'test_f1': 0.8019723296165466,\n",
              "  'test_loss': 0.5160344839096069}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uATPlOUHyxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a9b8b0a9-5d80-4580-acef-6f7895fdbed0"
      },
      "source": [
        "%tensorboard --logdir ./lightning_logs/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}