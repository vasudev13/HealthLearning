{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2HV3iaYiHpMt"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget -o dataset https://www.dropbox.com/s/vx57bs5ca4s9cuh/mednli-a-natural-language-inference-dataset-for-the-clinical-domain-1.0.0.zip\n",
    "!pip install transformers\n",
    "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXP4a68ySwf6",
    "outputId": "87039e87-f102-4504-c34f-493ce060f678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 15 03:42:49 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LyOsz0GsKouY"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "laOI3ayiHioT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y46F4WeKkpCB"
   },
   "outputs": [],
   "source": [
    "CONFIG={\n",
    "    'ZIP_PATH':'./mednli-a-natural-language-inference-dataset-for-the-clinical-domain-1.0.0.zip', # PATH TO ZIP FILE\n",
    "    'DATA_PATH':'./mednli-a-natural-language-inference-dataset-for-the-clinical-domain-1.0.0/', # PATH TO UNZIP DATASET\n",
    "    'sentence1':'sentence1',\n",
    "    'sentence2':'sentence2',\n",
    "    'labels':'gold_label',\n",
    "    'SEED':13,\n",
    "    'MAX_LEN':256,\n",
    "    'MODEL_NAME_OR_PATH':'dmis-lab/biobert-v1.1',\n",
    "    'LEARNING_RATE':2e-5,\n",
    "    'ADAM_EPSILON':1e-8,\n",
    "    'WEIGHT_DECAY':0.0,\n",
    "    'NUM_CLASSES':3,\n",
    "    'TRAIN_BS':32,\n",
    "    'VAL_BS':32,\n",
    "    'WARMUP_STEPS':0,\n",
    "    'MAX_EPOCHS':5,\n",
    "    'CHECKPOINT_DIR':'./checkpoints',\n",
    "    'NUM_WORKERS':2,\n",
    "    'PRECISION':16,\n",
    "    'MODEL_SAVE_NAME':'biobert_v1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqDpGKcEJBoM",
    "outputId": "726f80e8-7572-4e1f-a67e-42c9aca161cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    }
   ],
   "source": [
    "_=pl.seed_everything(CONFIG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4q1gW3DLOZHW"
   },
   "outputs": [],
   "source": [
    "class NLIDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self,max_len:int,tokenizer,sentence1,sentence2,labels):\n",
    "    super().__init__()\n",
    "    self.max_len=max_len\n",
    "    self.tokenizer=tokenizer\n",
    "    self.sentence1=sentence1\n",
    "    self.sentence2=sentence2\n",
    "    self.labels=labels\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.sentence1)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    sentence_1=self.sentence1[idx]\n",
    "    sentence_2=self.sentence2[idx]\n",
    "    encoded_input=self.tokenizer.encode_plus(\n",
    "        text=sentence_1,\n",
    "        text_pair=sentence_2,\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'labels':torch.tensor(self.labels[idx]),\n",
    "        'input_ids':encoded_input['input_ids'].view(-1),\n",
    "        'attention_mask':encoded_input['attention_mask'].view(-1),\n",
    "        'token_type_ids':encoded_input['token_type_ids'].view(-1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7YbKth_jCi6d"
   },
   "outputs": [],
   "source": [
    "def mnli_df(stage):\n",
    "  label_map={'entailment':0,'contradiction':1,'neutral':2}\n",
    "  df=pd.read_json(f\"{CONFIG['DATA_PATH']}/mli_{stage}_v1.jsonl\",lines=True,)\n",
    "  df=df[[CONFIG['sentence1'],CONFIG['sentence2'],CONFIG['labels']]]\n",
    "  df[CONFIG['labels']]=df[CONFIG['labels']].map(label_map)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DdMeI0vDggMp"
   },
   "outputs": [],
   "source": [
    "class NLIDataModel(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self,get_split_def):\n",
    "        super().__init__()\n",
    "        self.get_split_def=get_split_def\n",
    "\n",
    "    def prepare_data(self):\n",
    "        zip = zipfile.ZipFile(CONFIG['ZIP_PATH'])\n",
    "        zip.extractall()\n",
    "        self.tokenizer=transformers.AutoTokenizer.from_pretrained(CONFIG['MODEL_NAME_OR_PATH'])\n",
    "\n",
    "    def setup(self, stage):\n",
    "\n",
    "      if stage=='fit':\n",
    "        self.train_df,self.val_df=self.get_split_def('train'),self.get_split_def('dev')\n",
    "\n",
    "      if stage=='test':\n",
    "        self.test_df=self.get_split_def('test')\n",
    "\n",
    "    def get_dataset(self,df):\n",
    "      dataset = NLIDataset(max_len=CONFIG['MAX_LEN'],\n",
    "                               tokenizer=self.tokenizer,\n",
    "                               sentence1=df[CONFIG['sentence1']].values,\n",
    "                               sentence2=df[CONFIG['sentence2']].values,\n",
    "                               labels=df[CONFIG['labels']].values)\n",
    "      return dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "      train_dataset=self.get_dataset(self.train_df)\n",
    "      train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                     batch_size=CONFIG['TRAIN_BS'], \n",
    "                                                     shuffle=True, \n",
    "                                                     num_workers=CONFIG['NUM_WORKERS'])\n",
    "      \n",
    "      return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "      val_dataset=self.get_dataset(self.val_df)\n",
    "      val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                                     batch_size=CONFIG['VAL_BS'], \n",
    "                                                     shuffle=False, \n",
    "                                                     num_workers=CONFIG['NUM_WORKERS'])\n",
    "      \n",
    "      return val_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "      test_dataset=self.get_dataset(self.test_df)\n",
    "      test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                                     batch_size=CONFIG['VAL_BS'], \n",
    "                                                     shuffle=False, \n",
    "                                                     num_workers=CONFIG['NUM_WORKERS'])\n",
    "      \n",
    "      return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "X6roNgOB9JxT"
   },
   "outputs": [],
   "source": [
    "class NLIFineTuningModel(pl.LightningModule):\n",
    "\n",
    "  def __init__(self,model_name_or_path:str,\n",
    "               num_labels:int,\n",
    "               learning_rate:float,\n",
    "               adam_epsilon:float,\n",
    "               weight_decay:float,\n",
    "               max_len:int,\n",
    "               warmup_steps:int,\n",
    "               gpus:int,max_epochs:int,accumulate_grad_batches:int):\n",
    "    super().__init__()\n",
    "    self.model_name_or_path=model_name_or_path\n",
    "    self.num_labels=num_labels\n",
    "    \n",
    "    self.save_hyperparameters('learning_rate','adam_epsilon','weight_decay','max_len','gpus','accumulate_grad_batches','max_epochs','warmup_steps') \n",
    "\n",
    "    self.config = transformers.AutoConfig.from_pretrained(model_name_or_path, num_labels=self.num_labels)\n",
    "    self.model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name_or_path, config=self.config)\n",
    "    # self.model = nn.Sequential( \n",
    "    #     OrderedDict(\n",
    "    #         [\n",
    "    #          ('base',transformers.AutoModel.from_pretrained(model_name_or_path)),\n",
    "    #          ('classifier',nn.Linear(in_features=768,out_features=self.num_labels)),\n",
    "    #          ('softmax',nn.Softmax())\n",
    "    #         ]\n",
    "    #     )\n",
    "    # )\n",
    "    metrics = torchmetrics.MetricCollection([\n",
    "        torchmetrics.Accuracy(),\n",
    "        torchmetrics.F1(num_classes=3,average='macro')\n",
    "      ]\n",
    "    )\n",
    "    self.train_metrics=metrics.clone()\n",
    "    self.val_metrics=metrics.clone()\n",
    "\n",
    "\n",
    "  def forward(self,inputs):\n",
    "    return self.model(**inputs)\n",
    "  \n",
    "  def training_step(self,batch,batch_idx):\n",
    "    loss,logits=self(batch)[:2]\n",
    "    predictions=torch.argmax(logits,dim=1)\n",
    "    self.train_metrics(predictions,batch['labels'])\n",
    "    self.log_dict({'train_accuracy':self.train_metrics['Accuracy'],'train_f1':self.train_metrics['F1']}, on_step=False, on_epoch=True)\n",
    "    return {\n",
    "        'loss':loss,\n",
    "        'predictions':predictions,\n",
    "        'labels':batch['labels']\n",
    "    }\n",
    "  \n",
    "  def validation_step(self,batch,batch_idx):\n",
    "    loss,logits=self(batch)[:2]\n",
    "    predictions=torch.argmax(logits,dim=1)\n",
    "    self.val_metrics(predictions,batch['labels'])\n",
    "    self.log_dict({'val_accuracy':self.val_metrics['Accuracy'],'val_f1':self.val_metrics['F1']}, on_step=False, on_epoch=True)\n",
    "    return {\n",
    "        'loss':loss,\n",
    "        'predictions':predictions,\n",
    "        'labels':batch['labels']\n",
    "    }\n",
    "  \n",
    "  def test_step(self,batch,batch_idx):\n",
    "    loss,logits=self(batch)[:2]\n",
    "    predictions=torch.argmax(logits,dim=1)\n",
    "    self.val_metrics(predictions,batch['labels'])\n",
    "    self.log_dict({'test_accuracy':self.val_metrics['Accuracy'],'test_f1':self.val_metrics['F1']}, on_step=False, on_epoch=True)\n",
    "    return {\n",
    "        'loss':loss,\n",
    "        'predictions':predictions,\n",
    "        'labels':batch['labels']\n",
    "    }\n",
    "\n",
    "  def validation_epoch_end(self,outputs):\n",
    "    loss=torch.tensor([x['loss'] for x in outputs])\n",
    "    loss = loss.mean()\n",
    "    self.log('val_loss', loss, prog_bar=True,on_step=False, on_epoch=True )\n",
    "  \n",
    "  def training_epoch_end(self,outputs):\n",
    "    loss=torch.tensor([x['loss'] for x in outputs])\n",
    "    loss = loss.mean()\n",
    "    self.log('train_loss', loss, prog_bar=True,on_step=False, on_epoch=True )\n",
    "  \n",
    "  def setup(self, stage):\n",
    "    if stage == 'fit':\n",
    "      train_loader = self.train_dataloader()\n",
    "      self.total_steps = (\n",
    "          (len(train_loader.dataset) // (train_loader.batch_size * max(1, self.hparams.gpus)))\n",
    "          // self.hparams.accumulate_grad_batches * float(self.hparams.max_epochs)\n",
    "      )\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    model = self.model\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\",\"LayerNorm.bias\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "          {\n",
    "              \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "              \"weight_decay\": self.hparams.weight_decay,\n",
    "          },\n",
    "          {\n",
    "              \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "              \"weight_decay\": 0.0,\n",
    "          },\n",
    "    ]\n",
    "    optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.total_steps\n",
    "    )\n",
    "    scheduler = {\n",
    "        'scheduler': scheduler,\n",
    "        'interval': 'step',\n",
    "        'frequency': 1\n",
    "    }\n",
    "    return [optimizer] ,[scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q-zsAoT-Ggwz"
   },
   "outputs": [],
   "source": [
    "model_save_checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath=CONFIG['CHECKPOINT_DIR'],\n",
    "    filename=f\"{CONFIG['MODEL_SAVE_NAME']}\"+'-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuzWNRU_LqoF",
    "outputId": "9f33825d-c08e-470e-c4c6-3d844d6f4004"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=torch.cuda.device_count(),\n",
    "                     max_epochs=CONFIG['MAX_EPOCHS'],\n",
    "                     callbacks=[model_save_checkpoint],\n",
    "                     precision=CONFIG['PRECISION'],\n",
    "                     num_sanity_val_steps=0\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402,
     "referenced_widgets": [
      "c8e5f9385f35457e892f9b602dfb8546",
      "d07156a3379e4b62b124c34d6b614643",
      "8473a40a64f349168a5da693c122b0e7",
      "20ac5951d8e14c76a11743e97c572c55",
      "b9eb6bbf864a4edf92b5b72601ec3352",
      "4814d7112c3e490b887ca10354563c38",
      "5c688bbff25d45d69856f370cbcb49ac",
      "eabc600ea8fa46fb9d8e935880e5a1cf"
     ]
    },
    "id": "VAsiFQk9sIyX",
    "outputId": "593a6bd0-b7d2-40d6-c28f-0766c4a69e61",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                          | Params\n",
      "----------------------------------------------------------------\n",
      "0 | model         | BertForSequenceClassification | 108 M \n",
      "1 | train_metrics | MetricCollection              | 0     \n",
      "2 | val_metrics   | MetricCollection              | 0     \n",
      "----------------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "433.250   Total estimated model params size (MB)\n",
      "/home/va2134/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/va2134/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e30ab95d0649a297184dbb4c8930ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=NLIFineTuningModel(\n",
    "    model_name_or_path=CONFIG['MODEL_NAME_OR_PATH'],\n",
    "    num_labels=CONFIG['NUM_CLASSES'],\n",
    "    learning_rate=CONFIG['LEARNING_RATE'],\n",
    "    adam_epsilon=CONFIG['ADAM_EPSILON'],\n",
    "    weight_decay=CONFIG['WEIGHT_DECAY'],\n",
    "    max_len=CONFIG['MAX_LEN'],\n",
    "    warmup_steps=CONFIG['WARMUP_STEPS'],\n",
    "    max_epochs=trainer.max_epochs,\n",
    "    gpus=trainer.gpus,\n",
    "    accumulate_grad_batches=trainer.accumulate_grad_batches,\n",
    ")\n",
    "\n",
    "mnli_dm=NLIDataModel(get_split_def=mnli_df)\n",
    "trainer.fit(model,mnli_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVuzA8o-Vxnk",
    "outputId": "b3be092b-def0-4f8b-fb98-e3d93f45efda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_accuracy': tensor(0.9573, device='cuda:0'),\n",
       " 'train_f1': tensor(0.9573, device='cuda:0'),\n",
       " 'epoch': tensor(4.),\n",
       " 'train_loss': tensor(0.1442, device='cuda:0'),\n",
       " 'val_accuracy': tensor(0.8495),\n",
       " 'val_f1': tensor(0.8491),\n",
       " 'val_loss': tensor(0.5132)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "referenced_widgets": [
      "fcbcbafad72c4504a521975423c3a37d"
     ]
    },
    "id": "IQMDoVRl6LQC",
    "outputId": "fd123aa5-cae8-4529-84b6-a9aff67ad0ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/va2134/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39dd54e871c4b32b950d4cc4006b49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.8255977630615234,\n",
      " 'test_f1': 0.8256306648254395,\n",
      " 'test_loss': 0.47156623005867004}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_accuracy': 0.8255977630615234,\n",
       "  'test_f1': 0.8256306648254395,\n",
       "  'test_loss': 0.47156623005867004}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "-uATPlOUHyxD",
    "outputId": "a9b8b0a9-5d80-4580-acef-6f7895fdbed0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4a6f188a424e617b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4a6f188a424e617b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MedNLI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "20ac5951d8e14c76a11743e97c572c55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_41779b41eedd4783baefc30d83a9ecfa",
       "IPY_MODEL_e8ae0c9c4e144967872d4d91e41d4e40"
      ],
      "layout": "IPY_MODEL_267ff477bdd64c7d95cc5ba0ac29c325"
     }
    },
    "4814d7112c3e490b887ca10354563c38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31ab0fabf1b94e33841995dfd70e3753",
       "IPY_MODEL_aada892f80d14ba79b28be2f8c3e7a1e"
      ],
      "layout": "IPY_MODEL_209bfc5b0c6940a28cf3ce0351b878e3"
     }
    },
    "5c688bbff25d45d69856f370cbcb49ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f0cb6837c36a411f91c1135466473666",
       "IPY_MODEL_bfc7bba2aa3e4161bb42015794b2b1fe"
      ],
      "layout": "IPY_MODEL_6329fc1096eb4125803631509bd0d247"
     }
    },
    "8473a40a64f349168a5da693c122b0e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa2cdc6e7e79420bae526ea26b6d5fdf",
       "IPY_MODEL_27a031866a5a4097bbce40914dce4e4f"
      ],
      "layout": "IPY_MODEL_714a8adcd63e4027ab5c8b020cd46848"
     }
    },
    "b9eb6bbf864a4edf92b5b72601ec3352": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acb9b1254fdd416e8d39e5d9cf5ad101",
       "IPY_MODEL_d1ec4400c2914d02a12561b1b7e2c211"
      ],
      "layout": "IPY_MODEL_ba4fb451c73141708c50efca50e88954"
     }
    },
    "c8e5f9385f35457e892f9b602dfb8546": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_564ba44b7a4943f0bab2abb2be4801c6",
       "IPY_MODEL_40c43dd7106646518965eac2fc4211b0"
      ],
      "layout": "IPY_MODEL_c7f6c9187da64a34b984f36a6af71a84"
     }
    },
    "d07156a3379e4b62b124c34d6b614643": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_583fe45cb35049e4ac1e55757031715f",
       "IPY_MODEL_f64fa42eae474a4c8f3c570e7296f8d0"
      ],
      "layout": "IPY_MODEL_0792583f29c1416585008c08732299a7"
     }
    },
    "eabc600ea8fa46fb9d8e935880e5a1cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c73f97cddb648d2ae0962c7b2727b62",
       "IPY_MODEL_2e7a99602e0b438382b33cdb00864ce9"
      ],
      "layout": "IPY_MODEL_c9ff63f766a64ceb94e3a7d1607f4067"
     }
    },
    "fcbcbafad72c4504a521975423c3a37d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a92fae4ee84c45debd3a748c6daa5d08",
       "IPY_MODEL_6f5f8a458c0b40a083775cf1c208cec6"
      ],
      "layout": "IPY_MODEL_fc41cc2e6d184568acf0b1ae77049e6e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
